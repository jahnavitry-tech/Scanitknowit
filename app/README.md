# Scan It Know It - Application Architecture and File Structure

## Overview

This application follows a client-server architecture where the frontend runs in the browser and communicates with serverless functions deployed on Vercel.

## Architecture Diagram

```mermaid
graph TB
    A[User Browser] --> B[React Frontend]
    B --> C[Tesseract.js OCR]
    B --> D[Vercel Serverless Functions]
    D --> E[OpenFoodFacts API]
    D --> F[OpenBeautyFacts API]
    D --> G[Wikidata SPARQL]
    D --> H[Reddit API]
    D --> I[Hugging Face Inference API]
```

## Component Details

### 1. React Frontend

- **Location**: `/src`
- **Framework**: React with JavaScript
- **Styling**: Tailwind CSS
- **OCR**: Tesseract.js (client-side)
- **State Management**: React hooks

### 2. Vercel Serverless Functions

- **Location**: `/api`
- **Runtime**: Node.js
- **Deployment**: Automatic with Vercel

#### API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/analyze` | POST | Analyzes uploaded image for QR codes, text, objects, and captions |

### 3. Free/Open-Source APIs

#### Product Data APIs

- **OpenFoodFacts**: Food product data
- **OpenBeautyFacts**: Cosmetic product data
- **Wikidata**: General product information

#### Community APIs

- **Reddit**: User reviews and discussions

#### AI APIs

- **Hugging Face Inference**: Free tier for AI models

## File Structure

```
project-root/
â”œâ”€â”€ app/                      # Main application
â”‚   â”œâ”€â”€ src/                 # Frontend source code
â”‚   â”‚   â”œâ”€â”€ components/      # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ CameraPanel.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ AnalysisPanel.jsx
â”‚   â”‚   â”‚   â””â”€â”€ App.jsx
â”‚   â”‚   â””â”€â”€ main.jsx         # Entry point
â”‚   â”œâ”€â”€ api/                 # API endpoints
â”‚   â”‚   â””â”€â”€ analyze.js       # Main analysis endpoint
â”‚   â”œâ”€â”€ dist/                # Built assets (generated)
â”‚   â”œâ”€â”€ vite.config.js       # Vite configuration
â”‚   â”œâ”€â”€ vercel.json          # Vercel configuration
â”‚   â”œâ”€â”€ package.json         # Dependencies and scripts
â”‚   â””â”€â”€ .env                 # Environment variables
â”œâ”€â”€ scanitknowit-backend/    # Backend server (separate deployment)
â”‚   â”œâ”€â”€ server.js            # Main server file
â”‚   â”œâ”€â”€ .env.production      # Production environment variables
â”‚   â””â”€â”€ render.yaml          # Render deployment configuration
â”œâ”€â”€ DEPLOYMENT.md            # Deployment process and checklist
â”œâ”€â”€ README.md                # This file (Application architecture and file structure)
â””â”€â”€ ERRORS_AND_FIXES.md      # Errors and fixes documentation
```

## Data Flow

1. User captures/upload image through CameraPanel
2. Image is processed by multiple recognition methods:
   - QR codes detected with `jsQR` (highest priority, 0.95-0.99 confidence)
   - Text extracted with `tesseract.js`
   - Objects recognized with TensorFlow.js MobileNet
   - Captions generated with Hugging Face BLIP (optional)
3. Results are merged and ranked by confidence
4. Results displayed in AnalysisPanel

## Deployment Architecture

- **Frontend**: Static files served by Vercel
- **Backend**: Serverless functions automatically scaled
- **No databases**: All data fetched from external APIs
- **No proprietary services**: All free/open-source

## Benefits

- **No server costs**: Serverless functions only run when needed
- **Free APIs**: No ongoing costs for data services
- **Scalable**: Automatically scales with usage
- **Global CDN**: Fast worldwide access
- **Easy deployment**: One-click deploy to Vercel

## UI Components

### CameraPanel.jsx
- Simple file upload interface
- Image preview functionality
- Loading and error states
- Clean, modern design

### AnalysisPanel.jsx
- Google Lens-style results display
- Confidence bars with color coding
- Icons for different result types
- Responsive design for all screen sizes

## API Key Information

The only API key used in this application is for Hugging Face BLIP image captioning:

- **HF_API_TOKEN**: Enables AI-generated captions for images (like Google Lens descriptions)
- This is completely optional - QR detection and OCR work without it
- Your token is configured in the `.env` file

## Robust Error Handling

The API has been enhanced with comprehensive error handling:

- **File Validation**: Checks that uploaded files exist and are accessible
- **Non-Blocking Processing**: If one recognition method fails, others continue
- **Detailed Logging**: Each step is logged for debugging purposes
- **Resource Management**: Temporary files are automatically cleaned up
- **Cross-Platform Compatibility**: Works on Windows, macOS, and Linux

## Result Ranking

Results are ranked by confidence with the following priorities:
1. **QR Codes**: 0.95-0.99 confidence (highest priority)
2. **OCR Text**: 0.5-0.85 confidence
3. **BLIP Captions**: 0.75 confidence (if enabled)
4. **Object Recognition**: 0.3-0.6 confidence

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Open a pull request